{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer, AlbertForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained('twmkn9/albert-base-v2-squad2')\n",
    "model = AlbertForQuestionAnswering.from_pretrained('twmkn9/albert-base-v2-squad2')\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# start_positions = torch.tensor([1])\n",
    "# end_positions = torch.tensor([3])\n",
    "# outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n",
    "# loss, start_scores, end_scores = outputs[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which new peso notes were the highest created by 1944?\"\n",
    "answer_text = 'The first issue in 1942 consisted of denominations of 1, 5, 10 and 50 centavos and 1, 5, and 10 Pesos. The next year brought \"replacement notes\" of the 1, 5 and 10 Pesos while 1944 ushered in a 100 Peso note and soon after an inflationary 500 Pesos note. In 1945, the Japanese issued a 1,000 Pesos note. This set of new money, which was printed even before the war, became known in the Philippines as Mickey Mouse money due to its very low value caused by severe inflation. Anti-Japanese newspapers portrayed stories of going to the market laden with suitcases or \"bayong\" (native bags made of woven coconut or Corypha leaf strips) overflowing with the Japanese-issued bills. In 1944, a box of matches cost more than 100 Mickey Mouse pesos. In 1945, a kilogram of camote cost around 1000 Mickey Mouse pesos. Inflation plagued the country with the devaluation of the Japanese money, evidenced by a 60% inflation experienced in January 1944.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 235 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, answer_text)\n",
    "print('The input has a total of {:} tokens.'.format(len(input_ids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]             2\n",
      "▁which           56\n",
      "▁new             78\n",
      "▁pes         10,457\n",
      "o               111\n",
      "▁notes        2,434\n",
      "▁were            46\n",
      "▁the             14\n",
      "▁highest      1,554\n",
      "▁created        679\n",
      "▁by              34\n",
      "▁1944         2,921\n",
      "?                60\n",
      "\n",
      "[SEP]             3\n",
      "\n",
      "▁the             14\n",
      "▁first           64\n",
      "▁issue        1,513\n",
      "▁in              19\n",
      "▁1942         3,148\n",
      "▁consisted    3,597\n",
      "▁of              16\n",
      "▁denominations 19,515\n",
      "▁of              16\n",
      "▁1              137\n",
      ",                15\n",
      "▁5              331\n",
      ",                15\n",
      "▁10             332\n",
      "▁and             17\n",
      "▁50           1,222\n",
      "▁cent         5,802\n",
      "avo          13,884\n",
      "s                18\n",
      "▁and             17\n",
      "▁1              137\n",
      ",                15\n",
      "▁5              331\n",
      ",                15\n",
      "▁and             17\n",
      "▁10             332\n",
      "▁pes         10,457\n",
      "os              759\n",
      ".                 9\n",
      "▁the             14\n",
      "▁next           328\n",
      "▁year           159\n",
      "▁brought        809\n",
      "▁                13\n",
      "\"                 7\n",
      "re               99\n",
      "place         5,119\n",
      "ment          1,130\n",
      "▁notes        2,434\n",
      "\"                 7\n",
      "▁of              16\n",
      "▁the             14\n",
      "▁1              137\n",
      ",                15\n",
      "▁5              331\n",
      "▁and             17\n",
      "▁10             332\n",
      "▁pes         10,457\n",
      "os              759\n",
      "▁while          133\n",
      "▁1944         2,921\n",
      "▁ushered     26,553\n",
      "▁in              19\n",
      "▁a               21\n",
      "▁100            808\n",
      "▁pes         10,457\n",
      "o               111\n",
      "▁note         1,945\n",
      "▁and             17\n",
      "▁soon           651\n",
      "▁after           75\n",
      "▁an              40\n",
      "▁inflation   15,559\n",
      "ary           1,857\n",
      "▁500          3,033\n",
      "▁pes         10,457\n",
      "os              759\n",
      "▁note         1,945\n",
      ".                 9\n",
      "▁in              19\n",
      "▁1945         2,403\n",
      ",                15\n",
      "▁the             14\n",
      "▁japanese     1,095\n",
      "▁issued       2,212\n",
      "▁a               21\n",
      "▁1,000        5,925\n",
      "▁pes         10,457\n",
      "os              759\n",
      "▁note         1,945\n",
      ".                 9\n",
      "▁this            48\n",
      "▁set            309\n",
      "▁of              16\n",
      "▁new             78\n",
      "▁money          875\n",
      ",                15\n",
      "▁which           56\n",
      "▁was             23\n",
      "▁printed      5,317\n",
      "▁even           166\n",
      "▁before         115\n",
      "▁the             14\n",
      "▁war            176\n",
      ",                15\n",
      "▁became         178\n",
      "▁known          167\n",
      "▁in              19\n",
      "▁the             14\n",
      "▁philippines  3,737\n",
      "▁as              28\n",
      "▁mickey      12,022\n",
      "▁mouse        7,567\n",
      "▁money          875\n",
      "▁due            397\n",
      "▁to              20\n",
      "▁its             82\n",
      "▁very           253\n",
      "▁low            708\n",
      "▁value        1,923\n",
      "▁caused       1,497\n",
      "▁by              34\n",
      "▁severe       4,538\n",
      "▁inflation   15,559\n",
      ".                 9\n",
      "▁anti         1,082\n",
      "-                 8\n",
      "japanese      9,072\n",
      "▁newspapers   5,573\n",
      "▁portrayed    5,918\n",
      "▁stories      1,650\n",
      "▁of              16\n",
      "▁going          228\n",
      "▁to              20\n",
      "▁the             14\n",
      "▁market       1,135\n",
      "▁                13\n",
      "laden        14,415\n",
      "▁with            29\n",
      "▁suitcase    16,244\n",
      "s                18\n",
      "▁or              54\n",
      "▁                13\n",
      "\"                 7\n",
      "bay           7,011\n",
      "ong           3,279\n",
      "\"                 7\n",
      "▁                13\n",
      "(                 5\n",
      "native       21,525\n",
      "▁bags         9,089\n",
      "▁made           117\n",
      "▁of              16\n",
      "▁woven       20,570\n",
      "▁coconut     16,806\n",
      "▁or              54\n",
      "▁cory        15,608\n",
      "pha           7,190\n",
      "▁leaf         5,164\n",
      "▁strips      15,383\n",
      ")                 6\n",
      "▁overflow    20,285\n",
      "ing              68\n",
      "▁with            29\n",
      "▁the             14\n",
      "▁japanese     1,095\n",
      "-                 8\n",
      "issue        12,565\n",
      "d                43\n",
      "▁bills        8,958\n",
      ".                 9\n",
      "▁in              19\n",
      "▁1944         2,921\n",
      ",                15\n",
      "▁a               21\n",
      "▁box          1,649\n",
      "▁of              16\n",
      "▁matches      1,717\n",
      "▁cost         1,516\n",
      "▁more            91\n",
      "▁than           119\n",
      "▁100            808\n",
      "▁mickey      12,022\n",
      "▁mouse        7,567\n",
      "▁pes         10,457\n",
      "os              759\n",
      ".                 9\n",
      "▁in              19\n",
      "▁1945         2,403\n",
      ",                15\n",
      "▁a               21\n",
      "▁kil          5,786\n",
      "ogram        20,476\n",
      "▁of              16\n",
      "▁ca           1,658\n",
      "mote         20,209\n",
      "▁cost         1,516\n",
      "▁around         140\n",
      "▁1000         6,150\n",
      "▁mickey      12,022\n",
      "▁mouse        7,567\n",
      "▁pes         10,457\n",
      "os              759\n",
      ".                 9\n",
      "▁inflation   15,559\n",
      "▁plagued     20,903\n",
      "▁the             14\n",
      "▁country        475\n",
      "▁with            29\n",
      "▁the             14\n",
      "▁deva        16,078\n",
      "lu            2,377\n",
      "ation           857\n",
      "▁of              16\n",
      "▁the             14\n",
      "▁japanese     1,095\n",
      "▁money          875\n",
      ",                15\n",
      "▁evidence     1,445\n",
      "d                43\n",
      "▁by              34\n",
      "▁a               21\n",
      "▁                13\n",
      "60%          12,978\n",
      "▁inflation   15,559\n",
      "▁experienced  3,882\n",
      "▁in              19\n",
      "▁january        320\n",
      "▁1944         2,921\n",
      ".                 9\n",
      "\n",
      "[SEP]             3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "# For each token and its id...\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    \n",
    "    # If this is the [SEP] token, add some space around it to make it stand out.\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')\n",
    "    \n",
    "    # Print the token string and its ID in two columns.\n",
    "    print('{:<12} {:>6,}'.format(token, id))\n",
    "\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the input_ids for the first instance of the `[SEP]` token.\n",
    "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "# The number of segment A tokens includes the [SEP] token istelf.\n",
    "num_seg_a = sep_index + 1\n",
    "\n",
    "# The remainder are segment B.\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "# Construct the list of 0s and 1s.\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "# There should be a segment_id for every input token.\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our example through the model.\n",
    "start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                 token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the tokens with the highest `start` and `end` scores.\n",
    "k = 3 # number of top answers returned\n",
    "start_scores.detach().numpy()[0][0] = 0\n",
    "end_scores.detach().numpy()[0][0] = 0\n",
    "answer_start = torch.topk(start_scores, k, largest=True)\n",
    "answer_end = torch.topk(end_scores, k, largest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \"▁100\"\n",
      "Answer: \"▁500 ▁pesos ▁note\"\n"
     ]
    }
   ],
   "source": [
    "#no overlapping\n",
    "for index, token_index in enumerate(answer_start[1][0]):   \n",
    "    if answer_end[1][0][index] >= answer_start[1][0][index]: #end token after start token\n",
    "        if index == 0: # first (best) answer\n",
    "            answer = tokens[answer_start[1][0][index]]\n",
    "            for i in range(answer_start[1][0][index] + 1, answer_end[1][0][index] + 1):\n",
    "                if tokens[i][0:1] != '▁':\n",
    "                    answer += tokens[i]\n",
    "                else:\n",
    "                    answer += ' ' + tokens[i]\n",
    "            print('Answer: \"' + answer + '\"')\n",
    "        elif (answer_start[1][0][index] >= answer_end[1][0][index-1]) or (answer_start[1][0][index-1] >= answer_end[1][0][index]):\n",
    "            # ^start token of current span is after end token of previous span; ^end token of current span is before start of prev\n",
    "            answer = tokens[answer_start[1][0][index]]\n",
    "            for i in range(answer_start[1][0][index] + 1, answer_end[1][0][index] + 1):\n",
    "                if tokens[i][0:1] != '▁':\n",
    "                    answer += tokens[i]\n",
    "                else:\n",
    "                    answer += ' ' + tokens[i]\n",
    "            print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
